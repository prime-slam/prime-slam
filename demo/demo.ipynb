{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "\n",
    "from src.detection.lines.lsd import LSD\n",
    "from src.detection.points.orb import ORB\n",
    "from src.detection.points.sift import SIFT\n",
    "from src.geometry.util import clip_lines\n",
    "from src.keyframe_selection.every_nth_keyframe_selector import EveryNthKeyframeSelector\n",
    "from src.matching.lines.lbd import LBD\n",
    "from src.matching.points.orb_matcher import ORBMatcher\n",
    "from src.matching.points.sift_matcher import SIFTMatcher\n",
    "from src.relative_pose_estimation.rgbd_line_pose_estimator import RGBDLinePoseEstimator\n",
    "from src.geometry.transform import make_homogeneous_matrix\n",
    "from src.relative_pose_estimation.rgbd_point_pose_estimator import (\n",
    "    RGBDPointPoseEstimator,\n",
    ")\n",
    "\n",
    "from src.sensor.depth import DepthImage\n",
    "from src.sensor.rgb import RGBImage\n",
    "from src.sensor.rgbd import RGBDImage\n",
    "from src.slam.frontend import PrimeSLAMFrontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_cloud(points_3d):\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points_3d)\n",
    "\n",
    "    return point_cloud\n",
    "\n",
    "\n",
    "def get_line_set(lines_3d):\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "    points = []\n",
    "    lines = []\n",
    "\n",
    "    for i, edges in enumerate(lines_3d):\n",
    "        points.append(edges[0])\n",
    "        points.append(edges[1])\n",
    "        lines.append((2 * i, 2 * i + 1))\n",
    "\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "    return line_set\n",
    "\n",
    "\n",
    "def create_point_map(keyframes):\n",
    "    abs_poses = [kf.world_to_camera_transform for kf in keyframes]\n",
    "    depths = [kf.sensor_measurement.depth for kf in keyframes]\n",
    "    observations_batch = [kf.observations for kf in keyframes]\n",
    "\n",
    "    keypoints_batch = [\n",
    "        np.array([np.array([observation.x, observation.y]) for observation in observations])\n",
    "        for observations in observations_batch\n",
    "    ]\n",
    "\n",
    "    keypoints_3d_batch = [\n",
    "        depth.back_project_points(keypoints)\n",
    "        for keypoints, depth in zip(keypoints_batch, depths)\n",
    "    ]\n",
    "\n",
    "    return [\n",
    "        get_point_cloud(keypoints_3D).transform(np.linalg.inv(pose))\n",
    "        for keypoints_3D, pose in zip(keypoints_3d_batch, abs_poses)\n",
    "    ]\n",
    "\n",
    "\n",
    "def create_line_map(keyframes):\n",
    "    abs_poses = [kf.world_to_camera_transform for kf in keyframes]\n",
    "    depths = [kf.sensor_measurement.depth for kf in keyframes]\n",
    "    observations_batch = [kf.observations for kf in keyframes]\n",
    "\n",
    "    lines_batch = [\n",
    "        np.array(\n",
    "            [np.array([observation.start_point, observation.end_point]) for observation in observations]\n",
    "        ).reshape(-1, 4)\n",
    "        for observations in observations_batch\n",
    "    ]\n",
    "    lines_2d_shape = (-1, 2, 2)\n",
    "    lines_batch = [\n",
    "        clip_lines(\n",
    "            lines, height=depth.depth_map.shape[0], width=depth.depth_map.shape[1]\n",
    "        )\n",
    "        .astype(int)\n",
    "        .reshape(lines_2d_shape)\n",
    "        for lines, depth in zip(lines_batch, depths)\n",
    "    ]\n",
    "\n",
    "    lines_3d_batch = [\n",
    "        depth.back_project_lines(keypoints).reshape(-1, 2, 3)\n",
    "        for keypoints, depth in zip(lines_batch, depths)\n",
    "    ]\n",
    "    return [\n",
    "        get_line_set(lines_3D).transform(np.linalg.inv(pose))\n",
    "        for lines_3D, pose in zip(lines_3d_batch, abs_poses)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = Path(\"./data/rgb\")\n",
    "depth_path = Path(\"./data/depth\")\n",
    "intrinsics_path = Path(\"./data/intrinsics.txt\")\n",
    "\n",
    "images_paths = sorted(images_path.iterdir())\n",
    "depth_paths = sorted(depth_path.iterdir())\n",
    "intrinsics = make_homogeneous_matrix(np.genfromtxt(intrinsics_path))\n",
    "depth_scaler = 5000\n",
    "images_number = len(depth_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = \"LSD\"\n",
    "\n",
    "if features == \"ORB\":\n",
    "    extractor = ORB(nfeatures=1000)\n",
    "    matcher = ORBMatcher()\n",
    "    relative_pose_estimator = RGBDPointPoseEstimator(intrinsics, 30)\n",
    "    create_map = create_point_map\n",
    "elif features == \"SIFT\":\n",
    "    extractor = SIFT()\n",
    "    matcher = SIFTMatcher()\n",
    "    relative_pose_estimator = RGBDPointPoseEstimator(intrinsics, 30)\n",
    "    create_map = create_point_map\n",
    "elif features == \"LSD\":\n",
    "    extractor = LSD()\n",
    "    matcher = LBD()\n",
    "    relative_pose_estimator = RGBDLinePoseEstimator(intrinsics)\n",
    "    create_map = create_line_map\n",
    "else:\n",
    "    raise ValueError(f\"Unknown features: {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [io.imread(path) for path in images_paths]\n",
    "depths = [io.imread(path) for path in depth_paths]\n",
    "\n",
    "frames = [\n",
    "    RGBDImage(RGBImage(img), DepthImage(depth, intrinsics, depth_scaler))\n",
    "    for img, depth in zip(images, depths)\n",
    "]\n",
    "keyframe_selector = EveryNthKeyframeSelector(n=1)\n",
    "\n",
    "slam = PrimeSLAMFrontend(\n",
    "    extractor,\n",
    "    matcher,\n",
    "    relative_pose_estimator,\n",
    "    keyframe_selector,\n",
    "    init_pose=np.eye(4),\n",
    ")\n",
    "\n",
    "for frame in frames:\n",
    "    slam.process_frame(frame)\n",
    "\n",
    "o3d.visualization.draw_geometries(create_map(slam.keyframes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metrics",
   "language": "python",
   "name": "metrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
